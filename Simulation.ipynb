{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f3096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417931e4",
   "metadata": {},
   "source": [
    "## Computer Simulation\n",
    "\n",
    "We use the following three factors to model the percent of EV car sales in the U.S: Price (P), Charging Stations (C) and Range (R). We write the following model:\n",
    "\n",
    "\n",
    "$$\\mathrm{Rating} = w_p \\cdot f_p(P) + w_c \\cdot f_c(C) + w_r \\cdot f_r(R)$$\n",
    "\n",
    "**Rating**: We interpret a rating as the probability that a particular person would buy an EV over a regular car, and take the average of these to get a prediction for proportion of EVs bought.\n",
    "\n",
    "**weights**: Each person has a different set of preferences, $w_p$, $w_c$ and $w_r$. We sample these as:\n",
    "* $w_p \\sim N(0.6, 0.1)$\n",
    "* $w_c \\sim N(0.05 + \\frac{1 - w_p}{2}, 0.01^2)$\n",
    "* $w_r = 1 - w_p - w_c$\n",
    "\n",
    "**f**: this is a function that scores each factor between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160c0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for reported results\n",
    "np.random.seed(157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875cbfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weights(n=1):\n",
    "    w_p = np.random.normal(loc=0.6, scale=0.1, size=n)\n",
    "    w_c = (1 - w_p) / 2 + np.random.normal(loc=0.05, scale=0.01, size=n)\n",
    "    w_r = 1 - w_p - w_c\n",
    "    return w_p, w_c, w_r\n",
    "\n",
    "def sample_P(n=1):\n",
    "    return np.random.normal(loc=0.95, scale=0.2, size=n)\n",
    "    \n",
    "def sample_C(n=1):\n",
    "    return np.random.normal(loc=300000, scale=75000, size=n)\n",
    "    \n",
    "def sample_R(n=1):\n",
    "    return np.random.normal(loc=400, scale=70, size=n)\n",
    "\n",
    "def f_p(P):\n",
    "    return 1 - 1 / (1 + np.exp(-6 * (P - 1)))\n",
    "\n",
    "def f_c(C):\n",
    "    sample = 2 * (10 ** -6) * C\n",
    "    return np.clip(sample, 0, 1)\n",
    "\n",
    "def f_r(R):\n",
    "    sample = 0.04 * np.sqrt(np.clip(R - 100, a_min=0, a_max=None))\n",
    "    return np.clip(sample, 0, 1)\n",
    "\n",
    "def sample_rating(n):\n",
    "    w_p, w_c, w_r = sample_weights(n)\n",
    "    P, C, R = sample_P(n), sample_C(n), sample_R(n)\n",
    "    return w_p * f_p(P) + w_c * f_c(C) + w_r * f_r(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4b7b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.5877430710881961\n",
      "Median: 0.5979084379048134\n",
      "10% percentile: 0.383074836451778\n",
      "90% percentile: 0.7760753789442462\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100000\n",
    "ratings = sample_rating(num_samples)\n",
    "print(f\"Average: {np.mean(ratings)}\")\n",
    "print(f\"Median: {np.median(ratings)}\")\n",
    "print(f\"10% percentile: {np.percentile(ratings, 10)}\")\n",
    "print(f\"90% percentile: {np.percentile(ratings, 90)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696991b6",
   "metadata": {},
   "source": [
    "### Alternative Weight Sampler\n",
    "\n",
    "Samples weights from normal distributions (with different means), then normalizes result so that they sum to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fd4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weights_alt(n=1):\n",
    "    w_p = np.random.normal(loc=0.7, scale=0.1, size=n)\n",
    "    w_c = np.random.normal(loc=0.5, scale=0.1, size=n)\n",
    "    w_r = np.random.normal(loc=0.3, scale=0.1, size=n)\n",
    "    w_p, w_c, w_r = np.vstack([w_p, w_c, w_r]) / np.sum([w_p, w_c, w_r], axis=0)\n",
    "    return w_p, w_c, w_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b21aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.5974017869915615\n",
      "Median: 0.6038190009435745\n",
      "10% percentile: 0.4290335784881638\n",
      "90% percentile: 0.7548683421226783\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100000\n",
    "w_p, w_c, w_r = sample_weights_alt(num_samples)\n",
    "P, C, R = sample_P(num_samples), sample_C(num_samples), sample_R(num_samples)\n",
    "ratings = w_p * f_p(P) + w_c * f_c(C) + w_r * f_r(R)\n",
    "\n",
    "print(f\"Average: {np.mean(ratings)}\")\n",
    "print(f\"Median: {np.median(ratings)}\")\n",
    "print(f\"10% percentile: {np.percentile(ratings, 10)}\")\n",
    "print(f\"90% percentile: {np.percentile(ratings, 90)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
